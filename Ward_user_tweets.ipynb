{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City of London, City of London\n",
      "{'Hashtags': [], 'User': '110660896', 'Time': 'Thu Jul 21 18:27:29 +0000 2016', 'coordinates': {'coordinates': [-0.08160141, 51.47814436], 'type': 'Point'}, 'Text': '@snowythepyro @BBB_Mrs I hope you get a ticker-tape shower at the end using all the wasted corners from the square template!', 'Ward': 'Brunswick Park, Southwark'}\n",
      "316662\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "f = open( \"wards.txt\", \"r\" )\n",
    "wards = []\n",
    "for line in f:\n",
    "    wards.append(json.loads(line))\n",
    "wards=wards[0]\n",
    "print(wards[629])\n",
    "tweets = []\n",
    "with open('DataSet1.txt') as f:\n",
    "    for line in f:\n",
    "        tweets.append(json.loads(line))\n",
    "tweets=tweets[0]\n",
    "print(tweets[2])\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hashtags': [], 'User': '470441737', 'Time': 'Thu Jul 21 18:36:18 +0000 2016', 'coordinates': {'coordinates': [0.31055556, 51.67666667], 'type': 'Point'}, 'Text': 'Wind 1.6 mph NE. Barometer 1021.0 hPa, Rising slowly. Temperature 23.2 Â°C. Rain today 0.0mm. Humidity 55%', 'Ward': 'Riverside, Southwark'}\n"
     ]
    }
   ],
   "source": [
    "print(tweets[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1266803563', 10145), ('497145453', 5637), ('285513814', 4146), ('2324422680', 4116)]\n",
      "We have 1969 regular users.\n"
     ]
    }
   ],
   "source": [
    "#User selection \n",
    "from collections import Counter\n",
    "users=[]\n",
    "for tweet in tweets:\n",
    "    users.append(tweet[\"User\"])\n",
    "c=Counter(users)\n",
    "print(c.most_common(4))\n",
    "\n",
    "normal_users=[]\n",
    "for user in c.keys():\n",
    "    if c[user]>=20 and c[user]<=200:\n",
    "        normal_users.append(user)\n",
    "print(\"We have\",len(normal_users), \"regular users.\")\n",
    "\n",
    "#for i in range(len(tweets)):\n",
    "#    if tweets[i][\"User\"] in normal_users:\n",
    "#        tweets[i][\"Regular\"]=\"yes\"\n",
    "#    else:\n",
    "#        tweets[i][\"Regular\"]=\"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objects=[]\n",
    "counts=[]\n",
    "#for item in c.most_common(3):\n",
    "#    objects.append(item[0])\n",
    "#    counts.append(item[1])\n",
    "#objects.append(' ')\n",
    "#counts.append(0)\n",
    "#item=c.most_common()[11]\n",
    "#objects.append(item[0])\n",
    "#counts.append(item[1])\n",
    "#item=c.most_common()[15]\n",
    "#objects.append(item[0])\n",
    "##counts.append(item[1])\n",
    "#objects.append(' ')\n",
    "#counts.append(0)   \n",
    "\n",
    "\n",
    "for item in c.most_common():\n",
    "    objects.append(item[0])\n",
    "    counts.append(item[1])\n",
    "#print(objects,counts)\n",
    "\n",
    "#histogram of users\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "    \n",
    "values, base = np.histogram(counts, bins=20000)\n",
    "cumsum= np.cumsum(values)\n",
    "Cumsum=[0]\n",
    "for item in list(cumsum):\n",
    "    Cumsum.append(item)\n",
    "plt.plot(np.log10(np.abs(base)),1-Cumsum/Cumsum[-1], c='blue',linewidth=1.6)\n",
    "\n",
    "plt.xlabel('x: # tweets (base-10 logarithm)')\n",
    "plt.ylabel('P(X>x)')\n",
    "plt.title('Number of Tweets')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Users': ['3577004956', '3577004956', '362458146', '1186243334', '362458146', '3577004956', '362458146', '3577004956', '3577004956', '3577004956', '239039017', '239039017', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '362458146', '362458146', '20592132', '20592132', '470441737', '470441737', '3577004956', '3577004956', '3577004956', '3577004956', '21829533', '362458146', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '362458146', '362458146', '3577004956', '3577004956', '362458146', '3577004956', '3577004956', '20592132', '28560020', '3577004956', '3577004956', '362458146', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '20592132', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '362458146', '3577004956', '362458146', '3577004956', '3577004956', '20592132', '20592132', '3577004956', '3577004956', '140954107', '362458146', '146563615', '20592132', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '362458146', '3577004956', '3577004956', '3577004956', '20592132', '3577004956', '3577004956', '4049155695', '367105918', '367105918', '3577004956', '3577004956', '106030160', '106030160', '3577004956', '3577004956', '3577004956', '16747368', '3577004956', '3577004956', '3577004956', '362458146', '3577004956', '3577004956', '3577004956', '22839859', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '110492945', '20592132', '266140814', '3577004956', '3577004956', '3577004956', '3577004956', '3577004956', '1262459563', '3577004956', '3577004956', '409565561', '3577004956', '3577004956', '165118839', '362458146', '3577004956', '362458146'], 'Ward': 'Chessington South, Kingston upon Thames'}\n"
     ]
    }
   ],
   "source": [
    "#ward_users  users who visited a given ward\n",
    "ward_users= list()\n",
    "for i in range(len(wards)):\n",
    "    ward_users.append(dict())\n",
    "    users=[tweet['User'] \n",
    "          for tweet in tweets\n",
    "          if tweet['Ward']==wards[i] and tweet['Regular']==\"yes\"]\n",
    "    ward_users[i]['Users']=users\n",
    "    ward_users[i]['Ward']=wards[i]\n",
    "print(ward_users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'4164056524': 53, '467657610': 52, '73671161': 26, '310299026': 16, '15710574': 13, '2713301353': 13, '38053583': 10, '288314281': 9, '83848212': 9, '757011626': 3, '22344554': 2, '325582333': 2, '20374819': 2, '63709420': 2, '18596691': 1, '14310744': 1, '2180401488': 1, '18122647': 1, '2781046033': 1, '237188450': 1, '208807183': 1, '116239843': 1, '2411338591': 1, '910498710': 1, '220375447': 1, '108477416': 1, '30690139': 1, '2829402086': 1, '2976530147': 1, '4049155695': 1, '536548952': 1, '5391902': 1, '1919450683': 1, '2427216679': 1, '3650939775': 1, '2958179163': 1, '313950004': 1, '130276802': 1, '1573064797': 1, '2783907833': 1})\n",
      "[('4164056524', 53), ('467657610', 52), ('73671161', 26), ('310299026', 16), ('15710574', 13), ('2713301353', 13), ('38053583', 10), ('288314281', 9), ('83848212', 9), ('757011626', 3)]\n",
      "Ealing Broadway, Ealing\n"
     ]
    }
   ],
   "source": [
    "print(Counter(ward_users[100][\"Users\"]))\n",
    "print(Counter(ward_users[100][\"Users\"]).most_common(10))\n",
    "print(ward_users[100][\"Ward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_tweets  tweets from regular users \n",
    "user_tweets= list()\n",
    "for j in range(len(normal_users)):\n",
    "    user=normal_users[j]\n",
    "    user_tweets.append(dict())\n",
    "    texts=[tweet['Text'] \n",
    "          for tweet in tweets\n",
    "          if tweet['Regular']==\"yes\" and tweet['User']==user]\n",
    "    user_tweets[j]['Tweets']=texts\n",
    "    user_tweets[j]['User']=user\n",
    "print(len(user_tweets))\n",
    "print(user_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#most-visited person \n",
    "dataset=[]\n",
    "j=0\n",
    "for i in range(len(ward_users)):\n",
    "    ward=ward_users[i]\n",
    "    users=Counter(ward[\"Users\"])\n",
    "    users=users.most_common()\n",
    "    freq_visited=[user[0] for user in users if user[1]>3]\n",
    "    if len(freq_visited)>=15:\n",
    "        dataset.append(dict())\n",
    "        dataset[j][\"freq_visitor\"]=freq_visited\n",
    "        dataset[j][\"Ward\"]=ward[\"Ward\"]\n",
    "        dataset[j][\"Training\"]=dict()\n",
    "        dataset[j][\"Test\"]=dict()\n",
    "        j+=1\n",
    "print(j)\n",
    "#    print(freq_visited)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "import random\n",
    "#wards having by more than 30 regular visitors\n",
    "for i in range(len(dataset)):\n",
    "    ward=dataset[i][\"Ward\"]\n",
    "    ntrain=int(2*len(dataset[i][\"freq_visitor\"])/3)\n",
    "    train=random.sample(dataset[i][\"freq_visitor\"],ntrain)\n",
    "    test=[user \n",
    "          for user in dataset[i][\"freq_visitor\"]\n",
    "          if user not in train ]\n",
    "    training_texts=[tweet[\"Text\"] \n",
    "                    for tweet in tweets\n",
    "                    if tweet[\"Ward\"]==ward and tweet[\"User\"] in train]\n",
    "#    test_texts=[tweet[\"Text\"] \n",
    "#                    for tweet in tweets\n",
    "#                    if tweet[\"Ward\"]==ward and tweet[\"User\"] in test]    \n",
    "    dataset[i][\"Training\"][\"Users\"]=train\n",
    "    dataset[i][\"Test\"][\"Users\"]=test\n",
    "    dataset[i][\"Training\"][\"Tweets\"]=training_texts\n",
    "#    dataset[i][\"Test\"][\"Tweets\"]=test_texts\n",
    "print(dataset[0])       \n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User': '11953', 'Regular': 'no', 'Ward': 'Belmont, Sutton', 'coordinates': {'coordinates': [-0.19874312, 51.34710637], 'type': 'Point'}, 'Time': 'Thu Jul 21 18:27:15 +0000 2016', 'Text': \"Finally got round to reading this book (it's @FY60EBZ's and lovingly on loan). \\nTwenty pages in,â¦ https://t.co/3vcpnKAVma\", 'Hashtags': []}\n"
     ]
    }
   ],
   "source": [
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78650\n"
     ]
    }
   ],
   "source": [
    "aaa=[]\n",
    "for tweet in tweets:\n",
    "    if tweet['Regular']==\"yes\":\n",
    "        aaa.append(tweet)\n",
    "        \n",
    "print(len(aaa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "reg_user_tweets=[]\n",
    "for i in range(len(tweets)):\n",
    "    if tweets[i][\"User\"] in normal_users:\n",
    "        reg_user_tweets.append(tweets[i])\n",
    "print(len(reg_user_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wards': ['Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Haggerston, Hackney', 'Haggerston, Hackney', 'Haggerston, Hackney', 'Haggerston, Hackney', 'Haggerston, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney', 'Hoxton East & Shoreditch, Hackney'], 'User': '1903451832'}\n"
     ]
    }
   ],
   "source": [
    "#user_wards  regular users which wards a given user has visited\n",
    "user_wards= list()\n",
    "for i in range(len(normal_users)):\n",
    "    user_wards.append(dict())\n",
    "    ward=[tweet['Ward'] \n",
    "          for tweet in tweets\n",
    "          if tweet['User']==normal_users[i]]\n",
    "    user_wards[i]['Wards']=ward\n",
    "    user_wards[i]['User']=normal_users[i]\n",
    "print(user_wards[0])\n",
    "#most-visited ward \n",
    "#for i in range(len(user_wards)):\n",
    "#    user=user_wards[i]\n",
    "#    visited=Counter(user[\"Wards\"])\n",
    "#    visited=visited.most_common(3)\n",
    "#    freq_visited=[ward[0] for ward in visited if ward[1]>3]\n",
    "#    user_wards[i][\"most_visited\"]=freq_visited\n",
    "#print(user_wards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('DataSet.txt', 'w') as outfile:\n",
    "    json.dump(tweets, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
